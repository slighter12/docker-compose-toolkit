x-redis-cluster-service: &redis-cluster-service
  image: redis:8.2-alpine
  restart: unless-stopped
  deploy:
    resources:
      limits:
        cpus: ${REDIS_CPU_LIMIT}
        memory: ${REDIS_MEMORY_LIMIT}
  command: >
    redis-server
    --cluster-enabled yes
    --cluster-config-file nodes.conf
    --cluster-node-timeout 5000
    --maxmemory ${REDIS_MAXMEMORY}
    --maxmemory-policy ${REDIS_MAXMEMORY_POLICY}
  networks:
    - cache-redis-cluster-net

x-redis-sentinel-service: &redis-sentinel-service
  image: docker.io/bitnamilegacy/redis:8.2
  restart: unless-stopped
  deploy:
    resources:
      limits:
        cpus: ${REDIS_CPU_LIMIT}
        memory: ${REDIS_MEMORY_LIMIT}
  healthcheck:
    test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
    interval: 10s
    timeout: 5s
    retries: 5
  networks:
    - cache-redis-sentinel-net

x-redis-sentinel: &redis-sentinel
  image: docker.io/bitnamilegacy/redis-sentinel:8.2
  restart: unless-stopped
  environment:
    - REDIS_MASTER_HOST=redis-sentinel-master
    - REDIS_MASTER_PORT_NUMBER=6379
    - REDIS_MASTER_PASSWORD=${REDIS_PASSWORD}
    - REDIS_SENTINEL_QUORUM=2
  deploy:
    resources:
      limits:
        cpus: ${REDIS_CPU_LIMIT}
        memory: ${REDIS_MEMORY_LIMIT}
  healthcheck:
    test: ["CMD", "redis-cli", "-p", "26379", "ping"]
    interval: 10s
    timeout: 5s
    retries: 5
  networks:
    - cache-redis-sentinel-net
  depends_on:
    - redis-sentinel-master
    - redis-sentinel-replica-1
    - redis-sentinel-replica-2

x-valkey-cluster-service: &valkey-cluster-service
  image: valkey/valkey:9.0-alpine
  restart: unless-stopped
  deploy:
    resources:
      limits:
        cpus: ${VALKEY_CPU_LIMIT}
        memory: ${VALKEY_MEMORY_LIMIT}
  command: >
    valkey-server
    --cluster-enabled yes
    --cluster-config-file nodes.conf
    --cluster-node-timeout 5000
    --maxmemory ${VALKEY_MAXMEMORY}
    --maxmemory-policy ${VALKEY_MAXMEMORY_POLICY}
  networks:
    - cache-valkey-cluster-net

x-valkey-sentinel-service: &valkey-sentinel-service
  image: valkey/valkey:9.0-alpine
  restart: unless-stopped
  deploy:
    resources:
      limits:
        cpus: ${VALKEY_CPU_LIMIT}
        memory: ${VALKEY_MEMORY_LIMIT}
  healthcheck:
    test: ["CMD", "valkey-cli", "-a", "${VALKEY_PASSWORD}", "ping"]
    interval: 10s
    timeout: 5s
    retries: 5
  networks:
    - cache-valkey-sentinel-net

x-valkey-sentinel: &valkey-sentinel
  image: valkey/valkey:9.0-alpine
  restart: unless-stopped
  environment:
    - VALKEY_MASTER_HOST=valkey-sentinel-master
    - VALKEY_MASTER_PORT=6379
    - VALKEY_MASTER_PASSWORD=${VALKEY_PASSWORD}
    - VALKEY_SENTINEL_QUORUM=2
  deploy:
    resources:
      limits:
        cpus: ${VALKEY_CPU_LIMIT}
        memory: ${VALKEY_MEMORY_LIMIT}
  healthcheck:
    test: ["CMD", "valkey-cli", "-p", "26379", "ping"]
    interval: 10s
    timeout: 5s
    retries: 5
  networks:
    - cache-valkey-sentinel-net
  depends_on:
    - valkey-sentinel-master
    - valkey-sentinel-replica-1
    - valkey-sentinel-replica-2

x-kafka-base-service: &kafka-base-service
  image: confluentinc/cp-kafka:8.1.0
  restart: unless-stopped
  deploy:
    resources:
      limits:
        cpus: ${KAFKA_CPU_LIMIT}
        memory: ${KAFKA_MEMORY_LIMIT}
  networks:
    - mq-net
  command:
    - "bash"
    - "-c"
    - |
      set -m
      /etc/confluent/docker/run &
      sleep 5
      if [ ! -f /var/lib/kafka/data/cluster_id ]; then
        /bin/kafka-storage format --config /etc/kafka/kafka.properties --cluster-id 'MkU3OEVBNTcwNTJENDM2Qk' --ignore-formatted
      fi
      fg 1
  environment:
    KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    KAFKA_HEAP_OPTS: ${KAFKA_HEAP_OPTS}
    KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:${KAFKA_ADVERTISED_LISTENERS_INTERNAL_PROTOCOL},EXTERNAL:${KAFKA_ADVERTISED_LISTENERS_EXTERNAL_PROTOCOL},DOCKER:PLAINTEXT,CONTROLLER:PLAINTEXT
    KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
    KAFKA_PROCESS_ROLES: 'broker,controller'
    KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka-1:19096,2@kafka-2:19097,3@kafka-3:19098'
    KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
    CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'

x-kafka-healthcheck: &kafka-healthcheck
  interval: 10s
  timeout: 15s
  retries: 10

services:
  # === Cache Services ===
  # Redis Cluster
  redis-1:
    <<: *redis-cluster-service
    container_name: redis-1
    ports:
      - "7001:6379"

  redis-2:
    <<: *redis-cluster-service
    container_name: redis-2
    ports:
      - "7002:6379"

  redis-3:
    <<: *redis-cluster-service
    container_name: redis-3
    ports:
      - "7003:6379"

  redis-4:
    <<: *redis-cluster-service
    container_name: redis-4
    ports:
      - "7004:6379"

  redis-5:
    <<: *redis-cluster-service
    container_name: redis-5
    ports:
      - "7005:6379"

  redis-6:
    <<: *redis-cluster-service
    container_name: redis-6
    ports:
      - "7006:6379"

  redis-cluster-creator:
    image: redis:8.2-alpine
    container_name: redis-cluster-creator
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: "32M"
    command: >
      bash -c "sleep 5 &&
               redis-cli --cluster create redis-1:6379 redis-2:6379 redis-3:6379 redis-4:6379 redis-5:6379 redis-6:6379 --cluster-replicas 1 --cluster-yes"
    networks:
      - cache-redis-cluster-net
    depends_on:
      - redis-1
      - redis-2
      - redis-3
      - redis-4
      - redis-5
      - redis-6

  # Redis Sentinel
  redis-sentinel-master:
    <<: *redis-sentinel-service
    container_name: redis-sentinel-master
    ports:
      - "6379:6379"
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}

  redis-sentinel-replica-1:
    <<: *redis-sentinel-service
    container_name: redis-sentinel-replica-1
    ports:
      - "6380:6379"
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_MASTER_HOST=redis-sentinel-master
      - REDIS_MASTER_PORT_NUMBER=6379
      - REDIS_MASTER_PASSWORD=${REDIS_PASSWORD}
    depends_on:
      - redis-sentinel-master

  redis-sentinel-replica-2:
    <<: *redis-sentinel-service
    container_name: redis-sentinel-replica-2
    ports:
      - "6381:6379"
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_MASTER_HOST=redis-sentinel-master
      - REDIS_MASTER_PORT_NUMBER=6379
      - REDIS_MASTER_PASSWORD=${REDIS_PASSWORD}
    depends_on:
      - redis-sentinel-master

  redis-sentinel-1:
    <<: *redis-sentinel
    container_name: redis-sentinel-1
    ports:
      - "26379:26379"

  redis-sentinel-2:
    <<: *redis-sentinel
    container_name: redis-sentinel-2
    ports:
      - "26380:26379"

  redis-sentinel-3:
    <<: *redis-sentinel
    container_name: redis-sentinel-3
    ports:
      - "26381:26379"

  # === Valkey Services ===
  # Valkey Cluster
  valkey-1:
    <<: *valkey-cluster-service
    container_name: valkey-1
    ports:
      - "7101:6379"

  valkey-2:
    <<: *valkey-cluster-service
    container_name: valkey-2
    ports:
      - "7102:6379"

  valkey-3:
    <<: *valkey-cluster-service
    container_name: valkey-3
    ports:
      - "7103:6379"

  valkey-4:
    <<: *valkey-cluster-service
    container_name: valkey-4
    ports:
      - "7104:6379"

  valkey-5:
    <<: *valkey-cluster-service
    container_name: valkey-5
    ports:
      - "7105:6379"

  valkey-6:
    <<: *valkey-cluster-service
    container_name: valkey-6
    ports:
      - "7106:6379"

  valkey-cluster-creator:
    image: valkey/valkey:9.0-alpine
    container_name: valkey-cluster-creator
    deploy:
      resources:
        limits:
          cpus: "0.1"
          memory: "32M"
    command: >
      bash -c "sleep 5 &&
               valkey-cli --cluster create valkey-1:6379 valkey-2:6379 valkey-3:6379 valkey-4:6379 valkey-5:6379 valkey-6:6379 --cluster-replicas 1 --cluster-yes"
    networks:
      - cache-valkey-cluster-net
    depends_on:
      - valkey-1
      - valkey-2
      - valkey-3
      - valkey-4
      - valkey-5
      - valkey-6

  # Valkey Sentinel
  valkey-sentinel-master:
    <<: *valkey-sentinel-service
    container_name: valkey-sentinel-master
    ports:
      - "7201:6379"
    environment:
      - VALKEY_PASSWORD=${VALKEY_PASSWORD}

  valkey-sentinel-replica-1:
    <<: *valkey-sentinel-service
    container_name: valkey-sentinel-replica-1
    ports:
      - "7202:6379"
    environment:
      - VALKEY_PASSWORD=${VALKEY_PASSWORD}
      - VALKEY_MASTER_HOST=valkey-sentinel-master
      - VALKEY_MASTER_PORT=6379
      - VALKEY_MASTER_PASSWORD=${VALKEY_PASSWORD}
    depends_on:
      - valkey-sentinel-master

  valkey-sentinel-replica-2:
    <<: *valkey-sentinel-service
    container_name: valkey-sentinel-replica-2
    ports:
      - "7203:6379"
    environment:
      - VALKEY_PASSWORD=${VALKEY_PASSWORD}
      - VALKEY_MASTER_HOST=valkey-sentinel-master
      - VALKEY_MASTER_PORT=6379
      - VALKEY_MASTER_PASSWORD=${VALKEY_PASSWORD}
    depends_on:
      - valkey-sentinel-master

  valkey-sentinel-1:
    <<: *valkey-sentinel
    container_name: valkey-sentinel-1
    ports:
      - "27301:26379"

  valkey-sentinel-2:
    <<: *valkey-sentinel
    container_name: valkey-sentinel-2
    ports:
      - "27302:26379"

  valkey-sentinel-3:
    <<: *valkey-sentinel
    container_name: valkey-sentinel-3
    ports:
      - "27303:26379"

  # === Database Services ===
  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - "3306:3306"
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      TZ: UTC
    deploy:
      resources:
        limits:
          cpus: ${MYSQL_CPU_LIMIT}
          memory: ${MYSQL_MEMORY_LIMIT}
        reservations:
          cpus: ${MYSQL_CPU_RESERVATION}
          memory: ${MYSQL_MEMORY_RESERVATION}
    volumes:
      - "./data/mysql/data:/var/lib/mysql"
      - "./services/mysql/config:/etc/mysql/conf.d"
    healthcheck:
      test:
        [
          "CMD",
          "mysql",
          "-h",
          "localhost",
          "-u",
          "root",
          "-p${MYSQL_ROOT_PASSWORD}",
          "-e",
          "SELECT 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - db-net

  mongo:
    image: mongo
    container_name: mongo
    ports:
      - "27017:27017"
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
    deploy:
      resources:
        limits:
          cpus: ${MONGO_CPU_LIMIT}
          memory: ${MONGO_MEMORY_LIMIT}
        reservations:
          cpus: "0.2"
          memory: 128M
    volumes:
      - "./data/mongo/data:/data/db"
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5
    networks:
      - db-net

  timescaledb:
    image: timescale/timescaledb:latest-pg16
    container_name: timescaledb
    ports:
      - "5432:5432"
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_MAX_CONNECTIONS=${POSTGRES_MAX_CONNECTIONS}
    deploy:
      resources:
        limits:
          cpus: ${TIMESCALEDB_CPU_LIMIT}
          memory: ${TIMESCALEDB_MEMORY_LIMIT}
    volumes:
      - "./data/timescaledb/data:/var/lib/postgresql/data"
    command: postgres -c 'max_connections=${POSTGRES_MAX_CONNECTIONS}' -c 'max_parallel_workers=${POSTGRES_MAX_PARALLEL_WORKERS}' -c 'max_parallel_workers_per_gather=${POSTGRES_MAX_PARALLEL_WORKERS_PER_GATHER}'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - db-net

  # === Message Queue Services ===
  kafka-1:
    <<: *kafka-base-service
    container_name: kafka-1
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:19092,EXTERNAL://${DOCKER_HOST_IP}:9092,DOCKER://host.docker.internal:29092
      KAFKA_NODE_ID: 1
      KAFKA_LISTENERS: 'INTERNAL://:19092,EXTERNAL://:9092,DOCKER://:29092,CONTROLLER://:19096'
    volumes:
      - "./data/kafka/broker-1/data:/var/lib/kafka/data"
      - "./data/kafka/broker-1/logs:/var/log/kafka"
    healthcheck:
      <<: *kafka-healthcheck
      test:
        [
          "CMD-SHELL",
          "kafka-topics --list --bootstrap-server localhost:9092 || exit 1",
        ]

  kafka-2:
    <<: *kafka-base-service
    container_name: kafka-2
    ports:
      - "9093:9093"
      - "29093:29093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:19093,EXTERNAL://${DOCKER_HOST_IP}:9093,DOCKER://host.docker.internal:29093
      KAFKA_NODE_ID: 2
      KAFKA_LISTENERS: 'INTERNAL://:19093,EXTERNAL://:9093,DOCKER://:29093,CONTROLLER://:19097'
    volumes:
      - "./data/kafka/broker-2/data:/var/lib/kafka/data"
      - "./data/kafka/broker-2/logs:/var/log/kafka"
    healthcheck:
      <<: *kafka-healthcheck
      test:
        [
          "CMD-SHELL",
          "kafka-topics --list --bootstrap-server localhost:9093 || exit 1",
        ]

  kafka-3:
    <<: *kafka-base-service
    container_name: kafka-3
    ports:
      - "9094:9094"
      - "29094:29094"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:19094,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094,DOCKER://host.docker.internal:29094
      KAFKA_NODE_ID: 3
      KAFKA_LISTENERS: 'INTERNAL://:19094,EXTERNAL://:9094,DOCKER://:29094,CONTROLLER://:19098'
    volumes:
      - "./data/kafka/broker-3/data:/var/lib/kafka/data"
      - "./data/kafka/broker-3/logs:/var/log/kafka"
    healthcheck:
      <<: *kafka-healthcheck
      test:
        [
          "CMD-SHELL",
          "kafka-topics --list --bootstrap-server localhost:9094 || exit 1",
        ]

  rabbitmq:
    image: rabbitmq:3.12-management
    container_name: rabbitmq
    ports:
      - "5672:5672" # AMQP port
      - "15672:15672" # Management UI port
    restart: unless-stopped
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_VHOST}
      - RABBITMQ_ERLANG_COOKIE=unique-erlang-cookie
      - RABBITMQ_PLUGINS_EXPAND_DIR=/var/lib/rabbitmq/plugins-expand
    deploy:
      resources:
        limits:
          cpus: ${RABBITMQ_CPU_LIMIT}
          memory: ${RABBITMQ_MEMORY_LIMIT}
    volumes:
      - "./data/rabbitmq/data:/var/lib/rabbitmq"
      - "./data/rabbitmq/log:/var/log/rabbitmq"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - mq-net
    ulimits:
      nofile:
        soft: 65536
        hard: 65536

  # === Search Services ===
  elasticsearch:
    image: elasticsearch:7.16.2
    container_name: elasticsearch
    ports:
      - 9200:9200
      - 9300:9300
    restart: unless-stopped
    environment:
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ES_JAVA_OPTS=${ES_JAVA_OPTS}
      - bootstrap.memory_lock=true
      - cluster.name=${ELASTIC_CLUSTER_NAME}
      - discovery.type=single-node
      - node.name=${ELASTIC_NODE_NAME}
      - xpack.security.enabled=true
      - xpack.monitoring.enabled=true
      - xpack.ml.enabled=false
      - node.master=true
      - node.data=true
      - network.host=0.0.0.0
    deploy:
      resources:
        limits:
          cpus: ${ES_CPU_LIMIT}
          memory: ${ES_MEMORY_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - "./data/elasticsearch/data:/usr/share/elasticsearch/data"
      - "./data/elasticsearch/logs:/usr/share/elasticsearch/logs"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -s -f http://localhost:9200/_cat/health >/dev/null || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - search-net

  kibana:
    image: kibana:7.16.2
    container_name: kibana
    ports:
      - 5601:5601
    restart: unless-stopped
    environment:
      - elasticsearch.hosts=http://elasticsearch:9200
      - elasticsearch.password=${KIBANA_SYSTEM_PASSWORD}
      - elasticsearch.username=kibana_system
    networks:
      - search-net
    depends_on:
      - elasticsearch

  # === Observability Services ===
  pyroscope:
    image: pyroscope/pyroscope:latest
    container_name: pyroscope
    ports:
      - "4040:4040"
    restart: unless-stopped
    environment:
      - PYROSCOPE_LOG_LEVEL=info
      - PYROSCOPE_RETENTION_PERIOD=24h
      - PYROSCOPE_CONFIG=/etc/pyroscope/server.yml
    deploy:
      resources:
        limits:
          cpus: ${PYROSCOPE_CPU_LIMIT}
          memory: ${PYROSCOPE_MEMORY_LIMIT}
    volumes:
      - "./data/pyroscope/data:/var/lib/pyroscope"
      - "./services/pyroscope/server.yml:/etc/pyroscope/server.yml"
    command: server
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:4040/healthz",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s # 給予足夠的啟動時間
    networks:
      - observability-net

networks:
  cache-redis-cluster-net:
    driver: bridge

  cache-redis-sentinel-net:
    driver: bridge

  cache-valkey-cluster-net:
    driver: bridge

  cache-valkey-sentinel-net:
    driver: bridge

  db-net:
    driver: bridge

  mq-net:
    driver: bridge

  search-net:
    driver: bridge

  observability-net:
    driver: bridge
