services:
  # === Cache Services ===
  # Redis Cluster
  redis-1:
    image: redis:7.0
    container_name: redis-1
    ports:
      - "7001:6379"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    command: >
      redis-server 
      --cluster-enabled yes 
      --cluster-config-file nodes.conf 
      --cluster-node-timeout 5000
      --maxmemory ${REDIS_MAXMEMORY}
      --maxmemory-policy ${REDIS_MAXMEMORY_POLICY}
    networks:
      - cache-cluster-net

  redis-2:
    image: redis:7.0
    container_name: redis-2
    ports:
      - "7002:6379"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    command: >
      redis-server 
      --cluster-enabled yes 
      --cluster-config-file nodes.conf 
      --cluster-node-timeout 5000
      --maxmemory ${REDIS_MAXMEMORY}
      --maxmemory-policy ${REDIS_MAXMEMORY_POLICY}
    networks:
      - cache-cluster-net

  redis-3:
    image: redis:7.0
    container_name: redis-3
    ports:
      - "7003:6379"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    command: >
      redis-server 
      --cluster-enabled yes 
      --cluster-config-file nodes.conf 
      --cluster-node-timeout 5000
      --maxmemory ${REDIS_MAXMEMORY}
      --maxmemory-policy ${REDIS_MAXMEMORY_POLICY}
    networks:
      - cache-cluster-net

  redis-4:
    image: redis:7.0
    container_name: redis-4
    ports:
      - "7004:6379"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    command: >
      redis-server 
      --cluster-enabled yes 
      --cluster-config-file nodes.conf 
      --cluster-node-timeout 5000
      --maxmemory ${REDIS_MAXMEMORY}
      --maxmemory-policy ${REDIS_MAXMEMORY_POLICY}
    networks:
      - cache-cluster-net

  redis-5:
    image: redis:7.0
    container_name: redis-5
    ports:
      - "7005:6379"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    command: >
      redis-server 
      --cluster-enabled yes 
      --cluster-config-file nodes.conf 
      --cluster-node-timeout 5000
      --maxmemory ${REDIS_MAXMEMORY}
      --maxmemory-policy ${REDIS_MAXMEMORY_POLICY}
    networks:
      - cache-cluster-net

  redis-6:
    image: redis:7.0
    container_name: redis-6
    ports:
      - "7006:6379"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    command: >
      redis-server 
      --cluster-enabled yes 
      --cluster-config-file nodes.conf 
      --cluster-node-timeout 5000
      --maxmemory ${REDIS_MAXMEMORY}
      --maxmemory-policy ${REDIS_MAXMEMORY_POLICY}
    networks:
      - cache-cluster-net

  redis-cluster-creator:
    image: redis:7.0
    container_name: redis-cluster-creator
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: '32M'
    command: >
      bash -c "sleep 5 &&
               redis-cli --cluster create redis-1:6379 redis-2:6379 redis-3:6379 redis-4:6379 redis-5:6379 redis-6:6379 --cluster-replicas 1 --cluster-yes"
    networks:
      - cache-cluster-net
    depends_on:
      - redis-1
      - redis-2
      - redis-3
      - redis-4
      - redis-5
      - redis-6

  # Redis Sentinel
  redis-sentinel-master:
    image: bitnami/redis:7.0
    container_name: redis-sentinel-master
    ports:
      - "6379:6379"
    restart: unless-stopped
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cache-sentinel-net

  redis-sentinel-replica-1:
    image: bitnami/redis:7.0
    container_name: redis-sentinel-replica-1
    ports:
      - "6380:6379"
    restart: unless-stopped
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_MASTER_HOST=redis-sentinel-master
      - REDIS_MASTER_PORT_NUMBER=6379
      - REDIS_MASTER_PASSWORD=${REDIS_PASSWORD}
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cache-sentinel-net
    depends_on:
      - redis-sentinel-master

  redis-sentinel-replica-2:
    image: bitnami/redis:7.0
    container_name: redis-sentinel-replica-2
    ports:
      - "6381:6379"
    restart: unless-stopped
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_MASTER_HOST=redis-sentinel-master
      - REDIS_MASTER_PORT_NUMBER=6379
      - REDIS_MASTER_PASSWORD=${REDIS_PASSWORD}
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cache-sentinel-net
    depends_on:
      - redis-sentinel-master

  redis-sentinel-1:
    image: bitnami/redis-sentinel:7.0
    container_name: redis-sentinel-1
    ports:
      - "26379:26379"
    restart: unless-stopped
    environment:
      - REDIS_MASTER_HOST=redis-sentinel-master
      - REDIS_MASTER_PORT_NUMBER=6379
      - REDIS_MASTER_PASSWORD=${REDIS_PASSWORD}
      - REDIS_SENTINEL_QUORUM=2
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "26379", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cache-sentinel-net
    depends_on:
      - redis-sentinel-master
      - redis-sentinel-replica-1
      - redis-sentinel-replica-2

  redis-sentinel-2:
    image: bitnami/redis-sentinel:7.0
    container_name: redis-sentinel-2
    ports:
      - "26380:26379"
    restart: unless-stopped
    environment:
      - REDIS_MASTER_HOST=redis-sentinel-master
      - REDIS_MASTER_PORT_NUMBER=6379
      - REDIS_MASTER_PASSWORD=${REDIS_PASSWORD}
      - REDIS_SENTINEL_QUORUM=2
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "26379", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cache-sentinel-net
    depends_on:
      - redis-sentinel-master
      - redis-sentinel-replica-1
      - redis-sentinel-replica-2

  redis-sentinel-3:
    image: bitnami/redis-sentinel:7.0
    container_name: redis-sentinel-3
    ports:
      - "26381:26379"
    restart: unless-stopped
    environment:
      - REDIS_MASTER_HOST=redis-sentinel-master
      - REDIS_MASTER_PORT_NUMBER=6379
      - REDIS_MASTER_PASSWORD=${REDIS_PASSWORD}
      - REDIS_SENTINEL_QUORUM=2
    deploy:
      resources:
        limits:
          cpus: ${REDIS_CPU_LIMIT}
          memory: ${REDIS_MEMORY_LIMIT}
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "26379", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cache-sentinel-net
    depends_on:
      - redis-sentinel-master
      - redis-sentinel-replica-1
      - redis-sentinel-replica-2

  # === Database Services ===
  mysql:
    image: mysql:8.0
    container_name: mysql
    ports:
      - "3306:3306"
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      TZ: UTC
    deploy:
      resources:
        limits:
          cpus: ${MYSQL_CPU_LIMIT}
          memory: ${MYSQL_MEMORY_LIMIT}
        reservations:
          cpus: ${MYSQL_CPU_RESERVATION}
          memory: ${MYSQL_MEMORY_RESERVATION}
    volumes:
      - "./data/mysql/data:/var/lib/mysql"
      - "./services/mysql/config:/etc/mysql/conf.d"
    healthcheck:
      test: ["CMD", "mysql", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}", "-e", "SELECT 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - db-net

  mongo:
    image: mongo
    container_name: mongo
    ports:
      - "27017:27017"
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
    deploy:
      resources:
        limits:
          cpus: ${MONGO_CPU_LIMIT}
          memory: ${MONGO_MEMORY_LIMIT}
        reservations:
          cpus: '0.2'
          memory: 128M
    volumes:
      - "./data/mongo/data:/data/db"
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5
    networks:
      - db-net

  timescaledb:
    image: timescale/timescaledb:latest-pg16
    container_name: timescaledb
    ports:
      - "5432:5432"
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_MAX_CONNECTIONS=${POSTGRES_MAX_CONNECTIONS}
    deploy:
      resources:
        limits:
          cpus: ${TIMESCALEDB_CPU_LIMIT}
          memory: ${TIMESCALEDB_MEMORY_LIMIT}
    volumes:
      - "./data/timescaledb/data:/var/lib/postgresql/data"
    command: postgres -c 'max_connections=${POSTGRES_MAX_CONNECTIONS}' -c 'max_parallel_workers=${POSTGRES_MAX_PARALLEL_WORKERS}' -c 'max_parallel_workers_per_gather=${POSTGRES_MAX_PARALLEL_WORKERS_PER_GATHER}'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - db-net

  # === Message Queue Services ===
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    container_name: zookeeper
    ports:
      - "2181:2181"
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    deploy:
      resources:
        limits:
          cpus: ${ZOOKEEPER_CPU_LIMIT}
          memory: ${ZOOKEEPER_MEMORY_LIMIT}
    volumes:
      - "./data/zookeeper/data:/var/lib/zookeeper/data"
      - "./data/zookeeper/log:/var/lib/zookeeper/log"
    healthcheck:
      test: [ "CMD-SHELL", "echo stat | nc localhost 2181" ]
      interval: 10s
      timeout: 15s
      retries: 10
    networks:
      - mq-net

  kafka-1:
    image: confluentinc/cp-kafka:7.7.0
    container_name: kafka-1
    ports:
      - "9092:9092"
      - "29092:29092"
    restart: unless-stopped
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:19092,EXTERNAL://${DOCKER_HOST_IP}:9092,DOCKER://host.docker.internal:29092
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_BROKER_ID: 1
      KAFKA_HEAP_OPTS: ${KAFKA_HEAP_OPTS}
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:${KAFKA_ADVERTISED_LISTENERS_INTERNAL_PROTOCOL},EXTERNAL:${KAFKA_ADVERTISED_LISTENERS_EXTERNAL_PROTOCOL},DOCKER:PLAINTEXT
      KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT}
    deploy:
      resources:
        limits:
          cpus: ${KAFKA_CPU_LIMIT}
          memory: ${KAFKA_MEMORY_LIMIT}
    volumes:
      - "./data/kafka/broker-1/data:/var/lib/kafka/data"
      - "./data/kafka/broker-1/logs:/var/log/kafka"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --list --bootstrap-server localhost:9092 || exit 1"]
      interval: 10s
      timeout: 15s
      retries: 10
    networks:
      - mq-net
    depends_on:
      - zookeeper

  kafka-2:
    image: confluentinc/cp-kafka:7.7.0
    container_name: kafka-2
    ports:
      - "9093:9093"
      - "29093:29093"
    restart: unless-stopped
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:19093,EXTERNAL://${DOCKER_HOST_IP}:9093,DOCKER://host.docker.internal:29093
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_BROKER_ID: 2
      KAFKA_HEAP_OPTS: ${KAFKA_HEAP_OPTS}
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:${KAFKA_ADVERTISED_LISTENERS_INTERNAL_PROTOCOL},EXTERNAL:${KAFKA_ADVERTISED_LISTENERS_EXTERNAL_PROTOCOL},DOCKER:PLAINTEXT
      KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT}
    deploy:
      resources:
        limits:
          cpus: ${KAFKA_CPU_LIMIT}
          memory: ${KAFKA_MEMORY_LIMIT}
    volumes:
      - "./data/kafka/broker-2/data:/var/lib/kafka/data"
      - "./data/kafka/broker-2/logs:/var/log/kafka"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --list --bootstrap-server localhost:9093 || exit 1"]
      interval: 10s
      timeout: 15s
      retries: 10
    networks:
      - mq-net
    depends_on:
      - zookeeper

  kafka-3:
    image: confluentinc/cp-kafka:7.7.0
    container_name: kafka-3
    ports:
      - "9094:9094"
      - "29094:29094"
    restart: unless-stopped
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:19094,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094,DOCKER://host.docker.internal:29094
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_BROKER_ID: 3
      KAFKA_HEAP_OPTS: ${KAFKA_HEAP_OPTS}
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:${KAFKA_ADVERTISED_LISTENERS_INTERNAL_PROTOCOL},EXTERNAL:${KAFKA_ADVERTISED_LISTENERS_EXTERNAL_PROTOCOL},DOCKER:PLAINTEXT
      KAFKA_LOG4J_ROOT_LOGLEVEL: ERROR
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT}
    deploy:
      resources:
        limits:
          cpus: ${KAFKA_CPU_LIMIT}
          memory: ${KAFKA_MEMORY_LIMIT}
    volumes:
      - "./data/kafka/broker-3/data:/var/lib/kafka/data"
      - "./data/kafka/broker-3/logs:/var/log/kafka"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --list --bootstrap-server localhost:9094 || exit 1"]
      interval: 10s
      timeout: 15s
      retries: 10
    networks:
      - mq-net
    depends_on:
      - zookeeper

  rabbitmq:
    image: rabbitmq:3.12-management
    container_name: rabbitmq
    ports:
      - "5672:5672"    # AMQP port
      - "15672:15672"  # Management UI port
    restart: unless-stopped
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
      - RABBITMQ_DEFAULT_VHOST=${RABBITMQ_VHOST}
      - RABBITMQ_ERLANG_COOKIE=unique-erlang-cookie
      - RABBITMQ_PLUGINS_EXPAND_DIR=/var/lib/rabbitmq/plugins-expand
    deploy:
      resources:
        limits:
          cpus: ${RABBITMQ_CPU_LIMIT}
          memory: ${RABBITMQ_MEMORY_LIMIT}
    volumes:
      - "./data/rabbitmq/data:/var/lib/rabbitmq"
      - "./data/rabbitmq/log:/var/log/rabbitmq"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - mq-net
    ulimits:
      nofile:
        soft: 65536
        hard: 65536

  # === Search Services ===
  elasticsearch:
    image: elasticsearch:7.16.2
    container_name: elasticsearch
    ports:
      - 9200:9200
      - 9300:9300
    restart: always
    environment:
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ES_JAVA_OPTS=${ES_JAVA_OPTS}
      - bootstrap.memory_lock=true
      - cluster.name=${ELASTIC_CLUSTER_NAME}
      - discovery.type=single-node
      - node.name=${ELASTIC_NODE_NAME}
      - xpack.security.enabled=true
      - xpack.monitoring.enabled=true
      - xpack.ml.enabled=false
      - node.master=true
      - node.data=true
      - network.host=0.0.0.0
    deploy:
      resources:
        limits:
          cpus: ${ES_CPU_LIMIT}
          memory: ${ES_MEMORY_LIMIT}
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - "./data/elasticsearch/data:/usr/share/elasticsearch/data"
      - "./data/elasticsearch/logs:/usr/share/elasticsearch/logs"
    healthcheck:
      test: ["CMD-SHELL", "curl -s -f http://localhost:9200/_cat/health >/dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - search-net

  kibana:
    image: kibana:7.16.2
    container_name: kibana
    ports:
      - 5601:5601
    restart: always
    environment:
      - elasticsearch.hosts=http://elasticsearch:9200
      - elasticsearch.password=${KIBANA_SYSTEM_PASSWORD}
      - elasticsearch.username=kibana_system
    networks:
      - search-net
    depends_on:
      - elasticsearch

  # === Observability Services ===
  pyroscope:
    image: pyroscope/pyroscope:latest
    container_name: pyroscope
    ports:
      - "4040:4040"
    restart: unless-stopped
    environment:
      - PYROSCOPE_LOG_LEVEL=info
      - PYROSCOPE_RETENTION_PERIOD=24h
      - PYROSCOPE_CONFIG=/etc/pyroscope/server.yml
    deploy:
      resources:
        limits:
          cpus: ${PYROSCOPE_CPU_LIMIT}
          memory: ${PYROSCOPE_MEMORY_LIMIT}
    volumes:
      - "./data/pyroscope/data:/var/lib/pyroscope"
      - "./services/pyroscope/server.yml:/etc/pyroscope/server.yml"
    command: server
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4040/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s    # 給予足夠的啟動時間
    networks:
      - observability-net

networks:
  cache-cluster-net:
    driver: bridge
  
  cache-sentinel-net:
    driver: bridge
  
  db-net:
    driver: bridge

  mq-net:
    driver: bridge

  search-net:
    driver: bridge

  observability-net:
    driver: bridge
